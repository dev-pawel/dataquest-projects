{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam filter using Naive Bayes\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this project I am goint to build a probability algorytm using multinominal Naive Bayes. The aim of this project is to classify messages as spam or non-spam. To teach a model I will use a dataset from [The UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/sms+spam+collection). This dataset contains over 5,000 SMS messages that are labeled by humans as spam or not.\n",
    "\n",
    "### Summary of results\n",
    "\n",
    "Using Naive Bayes algorytm we are able to achieve accuracy over 98% which is satisfying.\n",
    "\n",
    "## Data exploration\n",
    "\n",
    "Lets start by reading the dataset as pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_sms = pd.read_csv('data//SMSSpamCollection', sep='\\t', header=None, names=['Label','SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5572, 2)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of rows and colums\n",
    "data_sms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_sms.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of spam and non-spam \n",
    "data_sms.Label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is 5572 SMS messages which were labeled as spam or ham (means non-spam). There is approximately 86% messages classified as non-spam and the rest is labeled spam.\n",
    "\n",
    "\n",
    "## Train/test validation\n",
    "\n",
    "Lets now randomly split our data into two datasets:\n",
    "- 80% training\n",
    "- 20% testing\n",
    "\n",
    "We can use training data to train our probability model and then we will use remaining data to check how accurate it is. Rule of thumb is to split data into 80% training and 20% testing data. From one side we want to hava as much data as possible to train our model but on the other hand we want to also have enought data to test our model against it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomizing dataset\n",
    "randomized_data = data_sms.sample(frac=1,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457, 2)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = randomized_data.head(int(len(randomized_data)*(80/100))).copy()\n",
    "training.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1115, 2)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = randomized_data.iloc[training.shape[0]:].copy()\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.86538\n",
       "spam    0.13462\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of spam and non-spam in training data\n",
    "training.Label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ham     0.868161\n",
       "spam    0.131839\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# % of spam and non-spam in test data\n",
    "test.Label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have got randomly split data approx 13% of the messages are labeled spam in both datasets which means they were randomly selected.\n",
    "\n",
    "## Data transformation\n",
    "\n",
    "Lets transform our datasets to enable us to check how many times each work occures in each message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic cleaning\n",
    "\n",
    "# Removing punctuation\n",
    "punctuation = string.punctuation\n",
    "training['SMS'] = training['SMS'].str.replace(r'[{}]+'.format(re.escape(punctuation)),' ').str.lower().str.strip()\n",
    "\n",
    "# Building vocabulary of unique words\n",
    "vocabulary=[]\n",
    "for sms in training['SMS']:\n",
    "    for word in sms.split():\n",
    "        if word not in vocabulary:\n",
    "            vocabulary.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cleaning using Natural Language processing\n",
    "\n",
    "# import nltk\n",
    "# sms_words=[]\n",
    "# vocabulary=[]\n",
    "# useless_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n",
    "\n",
    "# for index, sms in enumerate(training['SMS']):\n",
    "#     bag_of_words = nltk.word_tokenize(sms)\n",
    "#     bag_of_words_clean = []\n",
    "#     for word in bag_of_words:\n",
    "#         word = word.lower()\n",
    "#         if word not in useless_words:\n",
    "#             bag_of_words_clean.append(word)\n",
    "#             if word not in vocabulary:\n",
    "#                 vocabulary.append(word)\n",
    "#     training['SMS'].iloc[index] = ' '.join(bag_of_words_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7857"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have developed two approaches:\n",
    "- Basic cleaning: removing only punctiation and spliting words on whitespace,\n",
    "- Natural Language processing: tokenizing text and removing stop words as well as punctiation\n",
    "\n",
    "To our's amazement we got better results applying basic cleaning so we stick to this.\n",
    "We have created the vocabulary list contaning all unique words across our messages from training dataset. There is almost 7860 unique words. \n",
    "\n",
    "Lets now transform our dataset to have vocabulary words as columns and value at each row coresponding to how many times a particular work occurs in the SMS column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a dict with unique words filled with zeros on length of the dataset\n",
    "word_counts_per_sms={}\n",
    "for unique_word in vocabulary:\n",
    "    word_counts_per_sms[unique_word] = [0] * len(training['SMS'])\n",
    "\n",
    "# Incrementing corresponding row-column value by 1\n",
    "for index, sms in enumerate(training['SMS']):\n",
    "    for word in sms.split():\n",
    "#         if word in word_counts_per_sms: # new line\n",
    "        word_counts_per_sms[word][index] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_exp = pd.DataFrame(word_counts_per_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>yep</th>\n",
       "      <th>by</th>\n",
       "      <th>the</th>\n",
       "      <th>pretty</th>\n",
       "      <th>sculpture</th>\n",
       "      <th>yes</th>\n",
       "      <th>princess</th>\n",
       "      <th>are</th>\n",
       "      <th>...</th>\n",
       "      <th>prakesh</th>\n",
       "      <th>beauty</th>\n",
       "      <th>hides</th>\n",
       "      <th>secrets</th>\n",
       "      <th>n8</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>related</th>\n",
       "      <th>trade</th>\n",
       "      <th>arul</th>\n",
       "      <th>bx526</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>yep  by the pretty sculpture</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>yes  princess  are you going to make me moan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>welp apparently he retired</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 7859 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                           SMS  yep  by  the  pretty  \\\n",
       "0   ham                  yep  by the pretty sculpture    1   1    1       1   \n",
       "1   ham  yes  princess  are you going to make me moan    0   0    0       0   \n",
       "2   ham                    welp apparently he retired    0   0    0       0   \n",
       "\n",
       "   sculpture  yes  princess  are  ...  prakesh  beauty  hides  secrets  n8  \\\n",
       "0          1    0         0    0  ...        0       0      0        0   0   \n",
       "1          0    1         1    1  ...        0       0      0        0   0   \n",
       "2          0    0         0    0  ...        0       0      0        0   0   \n",
       "\n",
       "   jewelry  related  trade  arul  bx526  \n",
       "0        0        0      0     0      0  \n",
       "1        0        0      0     0      0  \n",
       "2        0        0      0     0      0  \n",
       "\n",
       "[3 rows x 7859 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_transformed = pd.concat([training.reset_index(drop=True),training_exp], axis=1)\n",
    "training_transformed.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have transformet the training dataset by adding new columns representing each word present in all SMS messages once. For every row in our dataset we incremented value by number of times each word occurs in the SMS column. If any word doesn't occur in respective row the corresponding column's value is 0.\n",
    "\n",
    "## Naive Bayes model\n",
    "\n",
    "Next we can start building our model. We need to compare probability that given message is spam and probability that given message is not-spam. We can do this by comparing this two equations :\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Spam|(w_{1},w_{2},...,w_{n}) \\propto P(Spam) \\times \\prod_{i=0}^{n} P (w_{i}|Spam)\n",
    "\\end{equation*}\n",
    "\n",
    "\\begin{equation*}\n",
    "P(Ham|(w_{1},w_{2},...,w_{n}) \\propto P(Ham) \\times \\prod_{i=0}^{n} P (w_{i}|Ham)\n",
    "\\end{equation*}\n",
    "\n",
    "To calculate the probability of words given spam we need to use:\n",
    "\\begin{equation}\n",
    "P(w_{i}|Spam) = \\frac{N_{w_{i}|Spam}+ \\alpha}{N_{Spam} + \\alpha \\times N_{Vocabulary}}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Lets start by calculating **P(Spam)** and **P(Ham)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability of P(Spam) and P(Ham)\n",
    "p_ham = training_transformed['Label'].value_counts(normalize=True)[0]\n",
    "p_spam = 1 - p_ham\n",
    "\n",
    "# Number of words in Spam dataset\n",
    "training_spam = training_transformed[training_transformed['Label']=='spam']\n",
    "n_words_spam = 0\n",
    "for sms in training_spam['SMS']:\n",
    "    n_words_spam += len(sms.split())\n",
    "\n",
    "# Number of words in Ham dataset\n",
    "training_ham = training_transformed[training_transformed['Label']=='ham']\n",
    "n_words_ham = 0\n",
    "for sms in training_ham['SMS']:\n",
    "    n_words_ham += len(sms.split())\n",
    "        \n",
    "# Vocabulary size\n",
    "n_words_voc = len(vocabulary)\n",
    "\n",
    "# Alpha value\n",
    "alpha = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets now create two dictionaries, where each key represents a unique word from our vocabulary. One for spam and another one for ham messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the probability of words given spam and ham\n",
    "words_given_spam = {}\n",
    "words_given_ham = {}\n",
    "\n",
    "for word in vocabulary:\n",
    "    words_given_spam[word] = (training_spam[word].sum() + alpha)/(n_words_spam+(alpha*n_words_voc))\n",
    "    words_given_ham[word] = (training_ham[word].sum() + alpha)/(n_words_ham+(alpha*n_words_voc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have created all parameters needed for above equations. **P(words|Spam)** and **P(words|Ham)** is kept in words_given_spam and words_given_ham directories respectively.\n",
    "\n",
    "## Message classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_message(sms):\n",
    "    \n",
    "    # transforim sms to list of strings, no punctuation\n",
    "    message = re.sub(r'[{}]+'.format(re.escape(punctuation)),' ',sms)\n",
    "    message = message.lower().strip().split()\n",
    "    \n",
    "    # calculating probability of spam and ham given message \n",
    "    p_spam_given_message = p_spam\n",
    "    p_ham_given_message = p_ham\n",
    "    for word in message:\n",
    "        if word in vocabulary:\n",
    "            p_word_given_spam = words_given_spam[word]\n",
    "            p_spam_given_message *=p_word_given_spam\n",
    "            \n",
    "            p_word_given_ham = words_given_ham[word]\n",
    "            p_ham_given_message *=p_word_given_ham\n",
    "            \n",
    "    # printing results\n",
    "    if p_ham_given_message > p_spam_given_message:\n",
    "        return 'ham'\n",
    "    elif p_spam_given_message > p_ham_given_message:\n",
    "        return 'spam'\n",
    "    else:\n",
    "        return 'needs human classification'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function *classify_message()* takes a message in and returns *spam* if probability of spam given message is greater then probability of ham given message. Otherwise it returns *ham*. If these two probabilities are equal then program can't classify the message so human assistance is required.\n",
    "\n",
    "Lets test this function on two messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label for sms1: spam\n",
      "Label for sms2: ham\n"
     ]
    }
   ],
   "source": [
    "# test based on two messages\n",
    "sms1 = 'WINNER!! This is the secret code to unlock the money: C3421.'\n",
    "sms2 = 'Sounds good, Tom, then see u there'\n",
    "print('Label for sms1: ' +classify_message(sms1))\n",
    "print('Label for sms2: ' +classify_message(sms2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like above two messages were classified correctly. Lets now check accuracy of our model against test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3482</th>\n",
       "      <td>ham</td>\n",
       "      <td>Wherre's my boytoy ? :-(</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2131</th>\n",
       "      <td>ham</td>\n",
       "      <td>Later i guess. I needa do mcat study too.</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3418</th>\n",
       "      <td>ham</td>\n",
       "      <td>But i haf enuff space got like 4 mb...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3424</th>\n",
       "      <td>spam</td>\n",
       "      <td>Had your mobile 10 mths? Update to latest Oran...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                                SMS predicted\n",
       "3482   ham                           Wherre's my boytoy ? :-(       ham\n",
       "2131   ham          Later i guess. I needa do mcat study too.       ham\n",
       "3418   ham             But i haf enuff space got like 4 mb...       ham\n",
       "3424  spam  Had your mobile 10 mths? Update to latest Oran...      spam"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['predicted'] = test['SMS'].apply(classify_message)\n",
    "test.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 98.7443946188341\n"
     ]
    }
   ],
   "source": [
    "correct = (test['Label'] == test['predicted']).sum()\n",
    "total = test.shape[0]\n",
    "print('Accuracy of model: ' + str(correct/total*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this project, we managed to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. The filter had an accuracy of 98.74% on the test set we used, which is a pretty good result."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
